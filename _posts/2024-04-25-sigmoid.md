---
layout: post
title: "Sigmoid: the 'Natural' Choice"
header-includes:
    - \usepackage{amsmath}
    - \usepackage{amsfonts}
---

One of the very first models studied in any introductory machine learning course is the logistic regression model for binary classification:

$$\hat y_i = \sigma(X_i \beta) \tag{1.0}$$

Here, $X_i = [  x_{i1}    x_{i2}  \dots   x_{id}  ]$ are the features (also called covariates) of an input we want to classify. For example, these could be the pixels of an image, or a vector representation of some text. We'll also assume $x_{i1} = 1$, so as to include a bias term in our model. $\beta$ is a $d$-dimensional column vector of our learnable model parameters, and $\hat y_i$ is the model output. The function $\sigma$ is the **sigmoid function**, and it is given by: 

$$\sigma(z) = \frac{1}{1 + \exp(-z)} \tag{1.1}$$

In an introductory ML course, the sigmoid function is produced seemingly out of nowhere, and it happens to be exactly what we need to make our model work:

- The range of $\sigma$ is $(0, 1)$, which means our model output $\hat y_i$ can be interpreted as a probability distribution (more on this later). Hence our model can make classification predictions simply by rounding $\hat y_i$ to the nearest integer, either 0 or 1.
- $\sigma$ is differentiable everywhere, and its derivative can be elegantly expressed as $\sigma'(z) = \sigma(z)(1 - \sigma(z))$. In particular the derivative is nowhere 0, because $\sigma(z)$ is within $(0,1)$ for any $z$. This is a useful property if we are training our model using gradient descent.

But certainly sigmoid isn't the only differentiable function to possess these desirable properties. What makes sigmoid so well-suited for binary classification? Where does the expression for sigmoid $(1.1)$ come from? In the following sections I will present an answer to these questions from a statistical perspective, and explain why sigmoid is in fact the most “natural” choice for our binary classification model. 

## The Exponential Family

We begin with an overview of the exponential family of distributions, perhaps a seemingly unrelated topic. A probability distribution with density $p(x \vert \theta)$ is said to belong to the exponential family if $p(x \vert \theta)$ can be written in the following form:

$$p(x \vert \theta) = h(x) \exp \Big( \eta(\theta)^\top T(x) - A(\eta(\theta))\Big) \tag{2.1}$$

- $\theta$ could be any set of parameters, and $\eta$ is a reparametrization function. The parameters $\eta(\theta)$ are called the **natural parameters** (or canonical parameters) of the distribution.
- $T(x)$ is called the **sufficient statistic** for the distribution (we'll see why).
- $A(\eta(\theta))$ is called the cumulant function. It can be interpreted as a normalization constant for the PDF. 
- $h(x)$ could be any nonnegative function.

It turns out that many common distributions belong to the exponential family, including the Bernoulli, Gaussian, Poisson, Gamma, and Beta distributions.

### Example: Bernoulli Distribution
As an example, let's see how the PDF of the Bernoulli distribution can be expressed in the form of (2.1). A common expression for the PDF of the Bernoulli is:

$$p(x \vert \theta) = \theta^x (1 - \theta)^{1-x}$$

where $\theta$ is a parameter in $[0, 1]$. This gives:

$$p(x \vert \theta) = \Big(\frac{\theta}{1-\theta}\Big)^x (1 - \theta)$$

$$= \exp \Big(x \log\Big(\frac{\theta}{1-\theta}\Big) + \log(1 - \theta) \Big) \label{2.2}$$

Note that \eqref{2.2} is in the desired form \eqref{2.1}:

- $\eta(\theta) = \log\big(\frac{\theta}{1-\theta}\big)$ is the natural parameter
- $T(x) = x$ is the sufficient statistic
- $A(\eta(\theta)) = - \log (1 - \theta)$ is a normalizing constant
- $h(x) = 1$

In this example, $\theta$ is called the **mean parameter** of the Bernoulli distribution. In general, distributions in the exponential family have mean parameters which are not necessarily equal to their natural parameters. Formally, the mean parameters of a distribution in the exponential family are defined as $\theta := \mathbb{E}_{x \sim p}[T(x)]$ , the expected value of the sufficient statistic. Note that since $T(x) = x$ for the Bernoulli distribution, this definition coincides with our intuition for the mean parameter of a Bernoulli distribution being the expected success rate: $\theta = \mathbb{E}_{x \sim p}[x]$. As another example, the mean parameters of the Gaussian distribution are the familiar $\theta = [ \mu \sigma^2 ]$, while its natural parameters are the (perhaps not-so-natural) $[\frac{\mu }{\sigma ^{2}}{\frac {1}{2\sigma ^{2}}}]$.

### Sufficient Statistics
Why should we care about the exponential family? One reason is that their sufficient statistics are easy to determine, which makes them valuable for parametric inference. Recall that a statistic is any function of random samples $X$ from a distribution. Informally, a statistic $T(X)$ is **sufficient** for a distribution $p(x \vert \theta)$ if we can estimate parameters $\theta$ using $T(X)$, and if there is no further information we can obtain from $X$ about $\theta$ that is not already included in $T(X)$. 

As an example, consider the Bernoulli distribution once again, parametrized by $\theta$. If we sample $x_1,...x_n \stackrel{iid}{\sim} Bernoulli(\theta)$, then knowing the sample mean $\frac{1}{n} \sum_{i=1}^n x_i$ is enough to estimate $\theta$. Indeed, the MLE estimate for $\theta$ is $\hat \theta = \frac{1}{n} \sum_{i=1}^n x_i$. Knowing anything more about $x_1,...,x_n$ could not give us a better estimate for $\theta$. We say that $\sum_{i=1}^n x_i$ is a sufficient statistic for the Bernoulli distribution (assuming $n$ is known beforehand). 

Notice that the joint distribution of samples $x_1,...,x_n$ drawn $iid$ from an arbitrary distribution in the exponential family is: 

$$p(x_1,...,x_n \vert \theta) = \Big(\prod_{i=1}^n h(x_i) \Big) \exp\Big( \eta(\theta)^\top \underbrace{\big(\sum_{i=1}^n T(x_i)\big)}_{\text{sufficient!}} - n A(\eta(\theta))\Big) \tag{2.3}$$

In the previous section we showed $T(x) = x$ for the Bernoulli distribution. It follows that $\sum_{i=1}^n T(x_i) = \sum_{i=1}^n x_i$ is precisely the sufficient statistic for the Bernoulli distribution! It can be shown that in the general case as well, $\sum_{i=1}^n T(x_i)$ is a sufficient statistic for any distribution in the exponential family.

Hence, all the information needed to estimate the parameters of an exponential-family distribution from $iid$ samples $x_1,...,x_n$ is contained in a single vector $\sum_{i=1}^n T(x_i)$ of fixed dimension (as opposed to dimension that grows with sample size $n$), and this vector can simply be read off the PDF (2.3) of the joint distribution. As an aside, it turns out that much more is true. The Pitman-Koopman-Darmois theorem states that the exponential family of distributions is the \textit{only} family of distributions (under a few mild assumptions) for which the sufficient statistics are finite-dimensional for arbitrarily large sample sizes. 

### Reparametrizing
Earlier, we computed a reparametrization $\eta(\theta) = \log\big(\frac{\theta}{1-\theta}\big)$ of the Bernoulli PDF which mapped its mean parameter $\theta$ to its natural parameter. Notice furthermore that the mapping is invertible, with inverse given by (does this look familiar?):

$$\theta = \frac{1}{1 + \exp(-\eta(\theta))}$$

It is now natural to ask whether it is always possible to reparametrize from the natural parameters $\eta$ to the mean parameters $\theta = \mathbb{E}_{x \sim p}[T(x)]$ for any distribution in the exponential family. If $\theta$ are the mean parameters, can we always find an $\eta(\theta)$ that is one-to-one? As it turns out, we can. Yet another beautiful property satisfied by any distribution in the exponential family is the following:

\[ \frac{\partial A(\eta)}{\partial \eta} = \mathbb{E}_{x \sim p}[T(x)] \tag{2.4} \]

\[ \frac{\partial^2 A(\eta)}{\partial \eta ^2} = \text{Var}_{x \sim p}[T(x)] \tag{2.5} \]

Here, $\eta := \eta(\theta)$ denotes the natural parameters and $A(\eta)$ is the cumulant function. Note that (2.4) is precisely the expression for the mean parameters $\theta$, so we can write (2.5) as:

$$\frac{\partial^2 A(\eta)}{\partial \eta ^2} = \frac{\partial \theta(\eta) }{\partial \eta} = \text{Var}_{x \sim p}[T(x)]$$

Since the variance $\text{Var}_{x \sim p}[T(x)]$ is a strictly positive quantity, it follows that $\dfrac{\partial \theta(\eta)}{\partial \eta} > 0$.

Therefore, we can always express the mean parameters $\theta$ as a function of $\eta$ (the function given by (2.4)), and this function is guaranteed to be strictly increasing, hence invertible.